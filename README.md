# Course_codes
Hi, This is Haoyang Han. Graduate from Northwestern University, I selected following courses:

EECS 495: Machine Learning Foundation<br>
EECS 495: Deep Learning Foundation<br>
EECS 495: Reinforcement Learning<br>
EECS 495: Intro to Database<br>



And Audited several courses as well. So in this repo I will try to bring course codes for following material:

1. Basic codes of ML and DL
2. Designing pattern of AB test
3. Basic code of Hadoop, Hive, Spark and Scala
4. SQL(Trigger, stored procedure), Mysqlconnector codes. 

---
Outline of predictive Analytics II:<br>
 Note 1: Fundamental of Non-parametric regression(jupyter notebook 1)<br>
	1. Maximum Likelihood Estimation<br>
	2. Nonlinear Least Squares<br>
	3. Bootstrapping; Information Matrix<br>
	4. Regularization: L1(Lasso), L2(Ridge); Variable Selection<br>
	5. Model Selection: Training error, testing error, bias/variance tradeoff, linear smoothers, cross validation<br>
	6. Naive Bayes<br>
	7. Imbalanced data & response classes.<br><br>
B. Note 2: Neural Networks & CART(Decision Tree)<br>
	1. Neural Networks(ANN, Feed-foward NN)<br>
	2. Visualizing non-parametric models<br>
	3. CART<br><br>
C. Note 3: KNN, K-D tree, Local weighting & Kernel Smoothing, GAM, PPR, Ensemble(bagging, stacking, boosting), GBDT, RF.<br>
	1. Nearest Neighbors<br>
	2. LLR & Kernel Smoothing<br>
	3. GAM<br>
	4. Bagging, Stacking, Boosting, GBDT, RF<br><br>
D. Note 4<br>
	SVM, Naive Bayes, PCA.


---
Other Materials:<br>
In this Chapter, some materials are codes but more 
Advanced Tree Models:<br>
	1. XGBoost<br>
	2. LightGBM<br>
	3. CatBoost<br>
	4. Conclusion: <br>
	a. whatâ€™s the difference between all tree-based models(CART, DT, RF, GBDT, XGB,LightGBM, CAT)<br>
	b. Linear model, and how to build them from scratch<br><br>
	
Deep learning<br>
	1. Mathematical proof of backward propagation<br>
	2. Tensorflow and PyTorch tutorial<br>
	3. Optimization<br>
	4. Materials related to CNN, RNN, LSTM, ResNet, Q-learning, MCMC, and BERT.<br>
	5. AWS, Colab, Azure and GPU<br>
D.   Bayesian Method in detail<br>
	
E.   Generative Model versus Discriminative Model<br>
F.    Confusing points<br>
	1. Interaction and Correlation<br>
	2. Difference Between Kernel in SVM and in this course<br>
	3. Codes(from scratch) and packages for implementing stacking method<br><br>
G.   All other Materials(Given by GitHub link)<br>
	1. Introduction to Computer Vision<br>
	2. Introduction to Natural Language Processing<br>
	3. Introduction to Reinforcement Learning<br>

H. Other Materials<br>
	Several Link which might be useful

https://wei2624.github.io/MachineLearning/sv_generative_model/



